{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T07:23:56.164415Z",
     "start_time": "2020-02-08T07:23:56.107567Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T07:24:05.362059Z",
     "start_time": "2020-02-08T07:23:59.567664Z"
    },
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from hw_grapheme.train_mixup import generate_stratified_k_fold_index, train_model\n",
    "from hw_grapheme.utils import load_model_weight\n",
    "from hw_grapheme.data_pipeline import create_dataloaders, load_data\n",
    "from hw_grapheme.model import EfficientNet_grapheme, EfficientNet_0\n",
    "from hw_grapheme.loss_func import Loss_combine\n",
    "\n",
    "# from torchtools.optim import RangerLars, RAdam\n",
    "# from one_cycle import OneCycleLR\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "# from warmup_scheduler import GradualWarmupScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T07:24:05.515644Z",
     "start_time": "2020-02-08T07:24:05.363057Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T07:24:09.240643Z",
     "start_time": "2020-02-08T07:24:05.519633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data done, shape: (50210, 224, 224), (50210,), (50210, 3)\n"
     ]
    }
   ],
   "source": [
    "# load data \n",
    "pickle_paths = [\n",
    "    \"../data/processed_data/size_224/train_data_0.pickle\",\n",
    "#     \"../data/processed_data/size_224/train_data_1.pickle\",\n",
    "#     \"../data/processed_data/size_224/train_data_2.pickle\",\n",
    "#     \"../data/processed_data/size_224/train_data_3.pickle\",\n",
    "]\n",
    "\n",
    "image_data, name_data, label_data = load_data(pickle_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T07:24:09.394230Z",
     "start_time": "2020-02-08T07:24:09.242638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data[-5][100:110, 100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T07:24:09.577735Z",
     "start_time": "2020-02-08T07:24:09.396224Z"
    }
   },
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"model\": \"efficient 0\",\n",
    "    \"pretrain\": False,\n",
    "    \"head_info\": \"1 fc\",\n",
    "    \"input_size\": \"224X224\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"image_processing\": \"mixup, cutmix\",\n",
    "    \"cutmix/mixup alpha\": 0.1,\n",
    "    'mixup_alpha' : 0.1,\n",
    "    'batch_size': 64,\n",
    "    'num_workers': 6,\n",
    "    'pin_memory': True,\n",
    "    'n_epoch': 120,\n",
    "    'n_splits': 5,\n",
    "    'random_seed': 2020,\n",
    "    'mix_precision': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T07:24:18.829921Z",
     "start_time": "2020-02-08T07:24:09.579730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "batch_size = configs['batch_size']\n",
    "num_workers = configs['num_workers'] \n",
    "pin_memory = configs['pin_memory']\n",
    "n_epoch = configs['n_epoch']\n",
    "n_splits = configs['n_splits']\n",
    "random_seed = configs['random_seed']\n",
    "mixed_precision = configs['mix_precision']\n",
    "\n",
    "train_idx_list, test_idx_list = generate_stratified_k_fold_index(\n",
    "    image_data, label_data, n_splits, random_seed\n",
    ")\n",
    "\n",
    "# create loss function\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = Loss_combine()\n",
    "\n",
    "# for discriminative lr\n",
    "# my_list = ['module._fc.weight', 'module._fc.bias']\n",
    "# params = list(filter(lambda kv: kv[0] in my_list, eff_b0.named_parameters()))\n",
    "# base_params = list(filter(lambda kv: kv[0] not in my_list, eff_b0.named_parameters()))\n",
    "# params = [kv[1] for kv in params]\n",
    "# base_params = [kv[1] for kv in base_params]\n",
    "\n",
    "# create data_transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        # transforms.RandomAffine(degrees=10, scale=(1.0, 1.15)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.0692], [0.2051]),\n",
    "        # transforms.ToPILImage(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.0692], [0.2051])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T12:28:13.727957Z",
     "start_time": "2020-01-25T12:28:13.552179Z"
    }
   },
   "source": [
    "pretrain = False\n",
    "eff_version = \"4\"\n",
    "\n",
    "eff_b0 = EfficientNet_grapheme(eff_version, pretrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T12:28:13.920229Z",
     "start_time": "2020-01-25T12:28:13.889987Z"
    }
   },
   "source": [
    "eff_b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T07:24:19.003452Z",
     "start_time": "2020-02-08T07:24:18.832911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20200208_152418'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T07:24:19.166013Z",
     "start_time": "2020-02-08T07:24:19.006443Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_NOTEBOOK_NAME=model_3_efficient_net\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "# os.environ['WANDB_NOTEBOOK_NAME'] = 'model_3_efficient_net'\n",
    "%env WANDB_NOTEBOOK_NAME=model_3_efficient_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-08T07:24:29.607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/noklam/bengali\" target=\"_blank\">https://app.wandb.ai/noklam/bengali</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/noklam/bengali/runs/rccgrljx\" target=\"_blank\">https://app.wandb.ai/noklam/bengali/runs/rccgrljx</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.25 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "Error generating diff: Command '['git', 'diff', '--submodule=diff', 'HEAD']' returned non-zero exit status 128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train dataloader...\n",
      "Creating test dataloader...\n",
      "Epoch 0/119\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e96ab6f6cee4b2db67b29ae555a41f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=620), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CHANNO.OOCLDM\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\cuda\\nccl.py:24: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 5.7107, root_acc: 0.1192, vowel_acc: 0.4798, consonant_acc: 0.6498, combined_acc: 0.3420\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99d8e7b75554caeaa5f2e4a2f09827d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val Loss: 1.6679, root_acc: 0.4104, vowel_acc: 0.8311, consonant_acc: 0.8205, combined_acc: 0.6181\n",
      "In epoch 0, highest val accuracy increases from 0.0 to 0.618137859106855.\n",
      "In epoch 0, lowest val loss decreases from 999 to 1.6678970346430912.\n",
      "\n",
      "Epoch 1/119\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f89a95bd8a4fb7be04255773f05af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=620), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrain = configs['pretrain']\n",
    "# eff_version = \"4\"\n",
    "mixup_alpha = configs['mixup_alpha']\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(zip(train_idx_list, test_idx_list)):\n",
    "    if i != 0:\n",
    "        continue\n",
    "    print(f\"Training fold {i}\")\n",
    "    MODEL_DIR = Path(f\"../model_weights/eff_0_with_mixup_cutmix_alpha_0.1/fold_{i}\")\n",
    "    MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "    # WandB â€“ Initialize a new run\n",
    "    # use your own user/project name\n",
    "    wandb.init(entity=\"noklam\", project='bengali',config=configs, group=current_time)\n",
    "    # Re-run the model without restarting the runtime, unnecessary after our next release\n",
    "    wandb.watch_called = False\n",
    "\n",
    "    \n",
    "    # create model\n",
    "    # eff_b0 = EfficientNet_grapheme(eff_version, pretrain)\n",
    "    eff_b0 = EfficientNet_0(pretrain)\n",
    "\n",
    "    #########################\n",
    "    # load_model_weight(eff_b0, \"../model_weights/eff_0_with_mixup_cutmix/fold_0/eff_0_low_loss.pth\")\n",
    "    #########################\n",
    "    if mixed_precision:\n",
    "        eff_b0 = apex.parallel.DistributedDataParallel(eff_b0)\n",
    "        eff_b0.to(\"cuda\")\n",
    "        eff_b0 = torch.nn.parallel.DistributedDataParallel(\n",
    "            eff_b0, device_ids=[0, 1], output_device=0\n",
    "        )\n",
    "        eff_b0, optimizer_ft = amp.initialize(\n",
    "            eff_b0, optimizer_ft, opt_level=\"O1\")\n",
    "    else:\n",
    "        eff_b0.to(\"cuda\")\n",
    "        eff_b0 = nn.DataParallel(eff_b0)\n",
    "        # Add W&B logging\n",
    "        wandb.watch(eff_b0, log='all')\n",
    "\n",
    "    # create optimizer\n",
    "    # optimizer_ft = RangerLars(eff_b0.parameters())\n",
    "    optimizer_ft = optim.Adam(eff_b0.parameters(), weight_decay=1e-5)\n",
    "\n",
    "    # create data loader\n",
    "    data_loaders = create_dataloaders(\n",
    "        image_data, name_data, label_data, train_idx, valid_idx,\n",
    "        data_transforms, batch_size, num_workers, pin_memory\n",
    "    )\n",
    "\n",
    "    # create lr scheduler\n",
    "    # exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    #     optimizer_ft, factor=0.5, patience=5,\n",
    "    # )\n",
    "#     cos_lr_scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "#         optimizer_ft, T_max=n_epoch,\n",
    "#     )\n",
    "#     # one_cycle_lr_scheduler = OneCycleLR(\n",
    "#     #     optimizer_ft, max_lr=0.01, steps_per_epoch=len(data_loaders[\"train\"]), epochs=n_epoch\n",
    "#     # )\n",
    "\n",
    "#     scheduler_warmup = GradualWarmupScheduler(\n",
    "#         optimizer_ft, multiplier=1, total_epoch=10, after_scheduler=cos_lr_scheduler\n",
    "#     )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    callbacks = {}\n",
    "\n",
    "    callbacks = train_model(\n",
    "        eff_b0, optimizer_ft, data_loaders,\n",
    "        mixed_precision, callbacks, mixup_alpha, num_epochs=n_epoch,\n",
    "        epoch_scheduler=None, save_dir=MODEL_DIR\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T13:55:17.399291Z",
     "start_time": "2020-02-06T13:54:15.096Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "save_root_dir = Path(\"../model_weights/eff_0_baseline\")\n",
    "save_root_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "config_save_path = save_root_dir/\"config.csv\"\n",
    "\n",
    "with open(config_save_path, \"w\") as f:\n",
    "    for key in configs.keys():\n",
    "        f.write(f\"{key},{configs[key]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T13:55:17.401285Z",
     "start_time": "2020-02-06T13:54:15.099Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Get a batch of training data for demo\n",
    "\n",
    "# visual_loader = DataLoader(\n",
    "#     train_dataset, batch_size=4,\n",
    "#     num_workers=num_workers, pin_memory=True,\n",
    "# )\n",
    "\n",
    "# inputs, a,b,c = next(iter(visual_loader))\n",
    "\n",
    "# # Make a grid from batch\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
